{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Experiment 7: Hidden Markov Model \n",
    "**Aim : Implement HMM to predict the sequential data.**\n",
    "\n",
    "The three fundamental problems of HMMs: \n",
    "\n",
    "1. **Likelihood:** Compute the likelihood of a given observation sequence.\n",
    "2. **Decoding:** Determine the most likely hidden state sequence for a given observation sequence.\n",
    "3. **Learning:** Learn the HMM parameters given an observation sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class HiddenMarkovModel:\n",
    "\n",
    "    \"\"\"A Hidden Markov Model (HMM).\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    states : array_like or numpy ndarray\n",
    "        List of states.\n",
    "\n",
    "    observations : array_like or numpy ndarray\n",
    "        Observations space array.\n",
    "\n",
    "    tp : array_like or numpy ndarray\n",
    "        Transition probability matrix which stores probability of\n",
    "        moving from state i (row) to state j (col).\n",
    "\n",
    "    ep : array_like or numpy ndarray\n",
    "        Emission probability matrix which stores probability of\n",
    "        seeing observation o (col) from state s (row).\n",
    "\n",
    "    pi : array_like or numpy ndarray\n",
    "        Initial state probabilities array.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, states, observations, tp, ep, pi):\n",
    "\n",
    "        self.states = np.array(states)\n",
    "        self.observations = np.array(observations)\n",
    "        self.num_states = self.states.shape[0]\n",
    "        self.num_observations = self.observations.shape[0]\n",
    "        self.tp = np.array(tp)\n",
    "        self.ep = np.array(ep)\n",
    "        self.pi = np.array(pi)\n",
    "\n",
    "    def likelihood(self, obs):\n",
    "        \"\"\"Compute the likelihood of an observation sequence.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        obs : array_like or numpy ndarray\n",
    "            Sequence of observations.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        prob : float\n",
    "            Probability likelihood for observation sequence.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        prob, _ = self.likelihood_forward(obs)\n",
    "        return prob\n",
    "\n",
    "    def likelihood_forward(self, obs):\n",
    "        \"\"\"Compute observation likelihood using the forward algorithm.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        obs : array_like or numpy ndarray\n",
    "            Sequence of observations of size T.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        prob : float\n",
    "            Probability likelihood for observation sequence.\n",
    "\n",
    "        alpha : numpy ndarray\n",
    "            Forward probability matrix of shape (num_states x T).\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        T = len(obs)\n",
    "        alpha = np.zeros((self.num_states, T))\n",
    "\n",
    "        # initialization\n",
    "        o_0 = self._get_observation_idx(obs[0])\n",
    "        alpha[:, 0] = self.pi * self.ep[:, o_0]\n",
    "\n",
    "        # recursion\n",
    "        for t in range(1, T):\n",
    "            o_t = self._get_observation_idx(obs[t])\n",
    "            alpha[:, t] = alpha[:, t-1].dot(self.tp) * self.ep[:, o_t]\n",
    "\n",
    "        # termination\n",
    "        prob = alpha[:, T-1].sum()\n",
    "\n",
    "        return prob, alpha\n",
    "\n",
    "    def likelihood_backward(self, obs):\n",
    "        \"\"\"Compute observation likelihood using the backward algorithm.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        obs : array_like or numpy ndarray\n",
    "            Sequence of observations of size T.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        prob : float\n",
    "            Probability likelihood for observation sequence.\n",
    "\n",
    "        beta : numpy ndarray\n",
    "            Backward probability matrix of shape (num_states x T).\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        T = len(obs)\n",
    "        beta = np.zeros((self.num_states, T))\n",
    "\n",
    "        # initialization\n",
    "        beta[:, T-1] = 1\n",
    "\n",
    "        # recursion\n",
    "        for t in range(T-2, -1, -1):\n",
    "            o_t1 = self._get_observation_idx(obs[t+1])\n",
    "            beta[:, t] = self.tp.dot(self.ep[:, o_t1] * beta[:, t+1])\n",
    "\n",
    "        # termination\n",
    "        o_0 = self._get_observation_idx(obs[0])\n",
    "        prob = self.pi.dot(self.ep[:, o_0] * beta[:, 0])\n",
    "\n",
    "        return prob, beta\n",
    "\n",
    "    def decode(self, obs):\n",
    "        \"\"\"Determine the best hidden sequence using the Viterbi algorithm.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        obs : array_like or numpy ndarray\n",
    "            Sequence of observations of size T.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        path : numpy ndarray\n",
    "            Sequence of states of size T.\n",
    "\n",
    "        prob : float\n",
    "            Probability likelihood for observation sequence along path.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        T = len(obs)\n",
    "        delta = np.zeros((self.num_states, T))\n",
    "\n",
    "        # initialization\n",
    "        o_0 = self._get_observation_idx(obs[0])\n",
    "        delta[:, 0] = self.pi * self.ep[:, o_0]\n",
    "\n",
    "        # recursion\n",
    "        for t in range(1, T):\n",
    "            o_t = self._get_observation_idx(obs[t])\n",
    "            delta_prev = delta[:, t-1].reshape(-1, 1)\n",
    "            delta[:, t] = (delta_prev * self.tp).max(axis=0) * self.ep[:, o_t]\n",
    "\n",
    "        # termination\n",
    "        path = self.states[delta.argmax(axis=0)]\n",
    "        prob = delta[:, T-1].max()\n",
    "\n",
    "        return path, prob\n",
    "\n",
    "    def learn(self, obs, iterations=1):\n",
    "        \"\"\"Learn parameters from an observation sequence using Baum-Welch.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        obs : array_like or numpy ndarray\n",
    "            Sequence of observations of size T.\n",
    "\n",
    "        iterations : int, optional\n",
    "            Number of Expectation-Maximization (EM) iterations.\n",
    "            Defaults to 1.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        for _ in range(iterations):\n",
    "            T = len(obs)\n",
    "\n",
    "            # expectation step\n",
    "            likelihood, alpha = self.likelihood_forward(obs)\n",
    "            _, beta = self.likelihood_backward(obs)\n",
    "            gamma = alpha * beta / (alpha * beta).sum(axis=0)\n",
    "            xi = np.zeros((self.num_states, self.num_states, T-1))\n",
    "            for t in range(T-1):\n",
    "                o_t1 = self._get_observation_idx(obs[t+1])\n",
    "                for i in range(self.num_states):\n",
    "                    xi[i, :, t] = alpha[i, t] * self.tp[i, :] \\\n",
    "                                    * self.ep[:, o_t1] * beta[:, t+1]\n",
    "            xi /= xi.sum(axis=(0, 1))\n",
    "\n",
    "            # maximization step\n",
    "            self.pi = gamma[:, 0]\n",
    "            self.tp = xi.sum(axis=2) / gamma[:, :-1].sum(axis=1).reshape(-1, 1)\n",
    "            for idx, o in enumerate(self.observations):\n",
    "                indices = np.argwhere(obs == o).flatten()\n",
    "                self.ep[:, idx] = gamma[:, indices].sum(axis=1) \\\n",
    "                    / gamma.sum(axis=1)\n",
    "\n",
    "    def _get_observation_idx(self, o):\n",
    "        \"\"\"Get the vocabulary index value of an observation.\"\"\"\n",
    "        return np.argwhere(self.observations == o).flatten().item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model parameters\n",
    "state_space = [\"hot\", \"cold\"]\n",
    "observation_space = [1, 2, 3]\n",
    "initial_probabilities = [0.8, 0.2]\n",
    "transition_probabilities = [[0.6, 0.4], [0.5, 0.5]]\n",
    "emission_probabilities = [[0.2, 0.4, 0.4], [0.5, 0.4, 0.1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "hmm = HiddenMarkovModel(state_space, observation_space, transition_probabilities, \n",
    "                        emission_probabilities, initial_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Likelihood\n",
    "\n",
    "Given an HMM $\\lambda = (A, B, \\pi)$ and an observation sequence $O$, determine the likelihood $P(O|\\lambda)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Observation sequence: [1, 2, 3, 2, 2, 1, 2]\n",
      "* Likelihood: 5.92e-04\n"
     ]
    }
   ],
   "source": [
    "# calculate likelihood\n",
    "observation_sequence = [1, 2, 3, 2, 2, 1, 2]\n",
    "likelihood = hmm.likelihood(observation_sequence)\n",
    "print(\"* Observation sequence: {}\".format(observation_sequence))\n",
    "print(\"* Likelihood: {:.2e}\".format(likelihood))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Decoding\n",
    "\n",
    "Given an observation sequence $O$ and an HMM $\\lambda = (A, B, \\pi)$, discover the best hidden state sequence $Q$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Observation sequence: [1, 2, 3, 2, 2, 1, 2]\n",
      "* Most likely hidden state path: ['hot' 'hot' 'hot' 'hot' 'hot' 'cold' 'hot']\n",
      "* Likelihood for observation sequence along path: 2.12e-05\n"
     ]
    }
   ],
   "source": [
    "# determine most likely state sequence\n",
    "path, prob = hmm.decode(observation_sequence)\n",
    "print(\"* Observation sequence: {}\".format(observation_sequence))\n",
    "print(\"* Most likely hidden state path: {}\".format(path))\n",
    "print(\"* Likelihood for observation sequence along path: {:.2e}\".format(prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Learning\n",
    "\n",
    "Given an observation sequence $O$ and the set of states in the HMM, learn the HMM parameters $A$, $B$, and $\\pi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBABILITIES BEFORE LEARNING\n",
      "-----------------------------\n",
      "* Initial:\n",
      "[0.8 0.2]\n",
      "\n",
      "* Transition:\n",
      "[[0.6 0.4]\n",
      " [0.5 0.5]]\n",
      "\n",
      "* Emission:\n",
      "[[0.2 0.4 0.4]\n",
      " [0.5 0.4 0.1]]\n"
     ]
    }
   ],
   "source": [
    "# print original parameters\n",
    "print(\"PROBABILITIES BEFORE LEARNING\")\n",
    "print(\"-----------------------------\")\n",
    "print(\"* Initial:\")\n",
    "print(hmm.pi)\n",
    "print(\"\\n* Transition:\")\n",
    "print(hmm.tp)\n",
    "print(\"\\n* Emission:\")\n",
    "print(hmm.ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn from observation sequence\n",
    "hmm.learn(observation_sequence, iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBABILITIES AFTER LEARNING\n",
      "----------------------------\n",
      "* Initial:\n",
      "[0.61804435 0.38195565]\n",
      "\n",
      "* Transition:\n",
      "[[0.60945272 0.39054728]\n",
      " [0.50990073 0.49009927]]\n",
      "\n",
      "* Emission:\n",
      "[[0.23642616 0.55648474 0.2070891 ]\n",
      " [0.35240033 0.59164734 0.05595234]]\n"
     ]
    }
   ],
   "source": [
    "# print parameters after learning\n",
    "print(\"PROBABILITIES AFTER LEARNING\")\n",
    "print(\"----------------------------\")\n",
    "print(\"* Initial:\")\n",
    "print(hmm.pi)\n",
    "print(\"\\n* Transition:\")\n",
    "print(hmm.tp)\n",
    "print(\"\\n* Emission:\")\n",
    "print(hmm.ep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
